## ðŸ”§ **1.2 Generation Controls**

These are parameters that control the randomness, diversity, and behavior of the modelâ€™s output.

---

### ðŸ”¹ **Temperature**

**Definition:**
Controls the **randomness** of predictions. A lower temperature makes the output more deterministic, while a higher temperature makes it more creative and diverse.

| Temperature | Behavior           |
| ----------- | ------------------ |
| 0.0         | Deterministic      |
| 0.7         | Balanced (default) |
| 1.0         | Creative / Varied  |
| >1.0        | Highly Random      |

**Use Cases:**

* `0.2` for formal writing or programming
* `0.8+` for poetry, storytelling

---

### ðŸ”¹ **Top-p (Nucleus Sampling)**

**Definition:**
Instead of picking from all tokens, it selects from the **smallest possible set of top tokens** whose cumulative probability exceeds *p* (e.g., 0.9).

* If `top-p = 1.0`, no filtering is applied.
* If `top-p = 0.9`, only the top tokens with 90% cumulative probability are considered.

**Top-p vs Temperature:**

* **Top-p** trims the token pool.
* **Temperature** controls how you pick from that pool.

**Tip:** Often used together with temperature.

---

### ðŸ”¹ **Frequency Penalty**

**Definition:**
Discourages the model from repeating the **same tokens** too often.

* A value between `0.0` and `2.0`.
* Higher = **less repetition** of frequent tokens.

**Example:**
Without frequency penalty, the model might say:

> "I love cats. Cats are amazing. Cats are fun."

With penalty:

> "I love cats. They are amazing and fun pets."

---

### ðŸ”¹ **Presence Penalty**

**Definition:**
Discourages the model from repeating **already mentioned ideas or concepts**, encouraging it to introduce **new topics**.

* Also ranges between `0.0` and `2.0`.
* Higher = more diverse content.

| Parameter         | Affects | Effect                                 |
| ----------------- | ------- | -------------------------------------- |
| Frequency Penalty | Tokens  | Penalizes repeated **words**           |
| Presence Penalty  | Ideas   | Penalizes repeated **concepts/themes** |

---

### ðŸ”¹ **Stopping Criteria**

**Definition:**
Conditions that **end the generation** of tokens.

#### Types of Stopping Conditions:

1. **Max Tokens**: Stop after a fixed number of tokens.
2. **Stop Sequences**: Stop when specific string(s) appear.

   * E.g., `"###"` or `"\nHuman:"`
3. **End of Completion**: Natural stop based on sentence or prompt structure.

**Use Cases:**

* For chatbots, stop when itâ€™s the user's turn to speak.
* For code generation, stop at the end of a function or comment block.

---

### ðŸ§  Summary Table

| Control           | Purpose                               |
| ----------------- | ------------------------------------- |
| Temperature       | Randomness of choices                 |
| Top-p             | Probabilistic filtering of token pool |
| Frequency Penalty | Reduces repetition of exact words     |
| Presence Penalty  | Promotes new ideas / themes           |
| Stopping Criteria | Halts output at desired boundaries    |

