## ğŸ› ï¸ 7.1 **Manual (from Scratch)**

Building agents **from scratch** means youâ€™re not relying on any high-level framework (like LangChain or AutoGen) â€” instead, you're directly using an LLM API (e.g., OpenAI, Anthropic, Cohere) and wiring together all components yourself.

This gives full control over logic, memory, tool use, and how your agent behaves.

---

### ğŸ”¹ **1. Direct LLM API Calls**

You directly send `POST` requests to an LLM endpoint like:

**Example (OpenAI Chat API):**

```json
POST https://api.openai.com/v1/chat/completions

{
  "model": "gpt-4",
  "messages": [
    { "role": "system", "content": "You are a helpful assistant." },
    { "role": "user", "content": "What's 10 + 25?" }
  ],
  "temperature": 0.7
}
```

This is the building block of all agent behavior. You manage:

* The message history
* System prompts
* Temperature / top-p / max tokens
* Any tool/function metadata

---

### ğŸ”¹ **2. Implementing the Agent Loop**

You manually implement the **reason-think-act-observe** cycle.

**Agent Loop Skeleton:**

```python
while True:
    # 1. Generate next action
    response = call_llm(messages)
    
    # 2. Check for action/tool invocation
    if "Action:" in response:
        tool_name, params = parse_tool(response)
        tool_result = invoke_tool(tool_name, params)

        # 3. Reflect on observation
        messages.append({"role": "assistant", "content": response})
        messages.append({"role": "tool", "content": tool_result})
    else:
        break  # Final answer reached
```

You control:

* Message injection
* Tool call pattern
* Observational feedback
* Halting criteria

---

### ğŸ”¹ **3. Parsing Model Output**

When tools are involved, you must **parse structured commands** from the modelâ€™s output.

**Example:**

```text
Thought: I need to search.
Action: search_web("Python jobs in Dhaka")
```

You can extract the action with regex or structured formatting. To help with this:

* Use prompt templates like:

  ```
  Always respond in this format:
  Thought: ...
  Action: tool_name("arg1", "arg2")
  ```

> For robustness, many developers prefer JSON-formatted outputs with strict schema validation.

---

### ğŸ”¹ **4. Error & Rate-Limit Handling**

When working with APIs, itâ€™s essential to handle:

* â— **Rate limits** (`429 Too Many Requests`)
* â— **API timeouts**
* â— **Invalid JSON or malformed model outputs**
* â— **Tool failures**

**Best Practices:**

* Exponential backoff + retries
* Validate JSON with schemas before acting
* Add logging and alerts
* Fallback to safe defaults

---

### âœ… Advantages of Manual Approach

* Full control over every component
* Lean, no extra dependencies
* Ideal for research or specialized agents

### âŒ Trade-offs

* Slower development
* Harder to scale and maintain
* Need to implement memory, planning, monitoring, etc.

