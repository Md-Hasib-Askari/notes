## üõ†Ô∏è **7.2 LLM Native "Function Calling"**

---

### üîπ Overview

Instead of making the model *say* ‚ÄúAction: search\_web()‚Äù in plain text, modern LLMs can **return a structured JSON object** to invoke tools directly.

This allows:

* Clean integration of tools
* Schema validation
* Fewer hallucinations
* Seamless agent loops

---

### üîπ **1. OpenAI Function Calling**

Introduced in mid-2023, OpenAI's function calling lets GPT-3.5/4 models **dynamically decide when and how to call tools**.

#### ‚öôÔ∏è How it works:

* You **define a function schema** (name, parameters, description).
* You send this to the model as part of the prompt.
* If the model decides the function is relevant, it **returns the function name + arguments in JSON.**

**Example schema:**

```json
{
  "name": "get_weather",
  "description": "Get weather info for a location",
  "parameters": {
    "type": "object",
    "properties": {
      "location": {
        "type": "string",
        "description": "City name"
      }
    },
    "required": ["location"]
  }
}
```

**Returned from GPT:**

```json
{
  "function_call": {
    "name": "get_weather",
    "arguments": "{ \"location\": \"Dhaka\" }"
  }
}
```

**Advantages:**

* Structured tool use
* No parsing needed
* Great for multi-turn loops

---

### üîπ **2. Gemini Function Calling (Google)**

Gemini (formerly Bard) supports **function calling** through its **function calling API**, very similar to OpenAI.

#### Features:

* JSON-based function definitions
* Supports multiple functions
* Good for Google ecosystem (Calendar, Gmail, Maps, etc.)

üîß Useful in Gemini Agents (via MakerSuite or Google AI Studio).

---

### üîπ **3. OpenAI Assistant API**

This is a **higher-level API abstraction** introduced in late 2023 for building multi-turn assistants.

#### Features:

* Built-in message history
* Persistent threads
* Native tool calling
* File attachments
* Streaming support

**Tool calling is built-in:**

```python
assistant = openai.beta.assistants.create(
  name="Math Tutor",
  tools=[{"type": "function", "function": math_eval_fn}],
  model="gpt-4-turbo"
)
```

**Benefit:**
You don't need to manage memory or conversation state manually ‚Äî OpenAI handles it via *Threads*.

---

### üîπ **4. Anthropic Tool Use (Claude)**

Anthropic‚Äôs Claude 3 models introduced **tool use** (a.k.a. ‚Äúfunction calling‚Äù) in early 2024.

#### Key Features:

* Uses JSON tool call outputs
* Supports multiple tools
* Claude is conservative in tool invocation (less hallucination)
* Focuses on transparency and trustworthiness

**Tool call format:**

```json
{
  "tool_use": {
    "name": "search_web",
    "input": { "query": "Claude function calling" }
  }
}
```

> Claude‚Äôs tool use is especially strong in **multi-agent or dialog-heavy setups**, thanks to its structured reasoning.

---

### ‚úÖ Summary Table

| Provider         | Tool Use Support                | Format | Ideal For                                    |
| ---------------- | ------------------------------- | ------ | -------------------------------------------- |
| OpenAI           | ‚úÖ Function Call / Assistant API | JSON   | General purpose agents, fine-grained control |
| Gemini (Google)  | ‚úÖ Function Calling              | JSON   | Google integrations, web tasks               |
| Anthropic Claude | ‚úÖ Tool Use (Claude 3)           | JSON   | Safe tool use, multi-turn logic              |
| Mistral/Mixtral  | ‚ùå Not Yet                       | ‚Äî      | Open-weight, no native support               |

