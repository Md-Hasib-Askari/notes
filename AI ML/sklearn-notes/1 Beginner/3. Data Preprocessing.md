## ðŸŸ¢ Beginner Level

### 3. Data Preprocessing

Data preprocessing is a crucial step to clean and transform raw data before feeding it into a model.

---

### ðŸ“Œ 1. Train-Test Split

Separate your dataset into training and testing sets.

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

---

### ðŸ“Œ 2. Handling Missing Values

**Check for missing values:**

```python
import pandas as pd
df.isnull().sum()
```

**Impute missing values:**

```python
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='mean')  # or 'median', 'most_frequent'
X_imputed = imputer.fit_transform(X)
```

---

### ðŸ“Œ 3. Feature Scaling

**Standardization (zero mean, unit variance):**

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

**Min-Max Normalization (scales between 0 and 1):**

```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
```

---

### ðŸ“Œ 4. Encoding Categorical Variables

**Label Encoding:**

```python
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
y_encoded = le.fit_transform(y)
```

**One-Hot Encoding:**

```python
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(sparse=False)
X_encoded = encoder.fit_transform(X_categorical)
```

---

### ðŸ“Œ 5. Combine Preprocessing Steps (Optional)

```python
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_features),
    ('cat', OneHotEncoder(), categorical_features)
])
```
