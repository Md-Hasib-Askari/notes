## ðŸ”µ Advanced Level

### 14. Time Series with Scikit-learn

Scikit-learn is **not specifically designed** for time series, but you can still handle many time-based tasks with some creativity and care.

---

### ðŸ“Œ 1. Limitations of Scikit-learn for Time Series

* No built-in time series models (like ARIMA, ETS)
* Shuffling during cross-validation can break temporal order
* Feature engineering (lags, rolling stats) must be manual

âœ… Use Scikit-learn mostly for **feature-based forecasting** and **machine learning pipelines** on time series data.

---

### ðŸ“Œ 2. Rolling Windows & Lag Features

Lag features represent past values as input featuresâ€”standard approach for ML-based forecasting.

```python
import pandas as pd

# Create lag features
df['lag_1'] = df['target'].shift(1)
df['lag_2'] = df['target'].shift(2)

# Drop NA rows
df.dropna(inplace=True)
```

âœ… Add rolling means, max, std for trends:

```python
df['rolling_mean_3'] = df['target'].rolling(window=3).mean()
```

---

### ðŸ“Œ 3. Train-Test Split in Time Series

Use chronological split to avoid data leakage:

```python
train_size = int(len(df) * 0.8)
train, test = df[:train_size], df[train_size:]
```

---

### ðŸ“Œ 4. TimeSeriesSplit for CV

Use `TimeSeriesSplit` to preserve the order of time series during cross-validation.

```python
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)
for train_idx, test_idx in tscv.split(X):
    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
```

âœ… Mimics walk-forward validation.

---

### ðŸ§  Tips

* Always sort data by time before modeling.
* Use external time series libraries (e.g., `statsmodels`, `sktime`, `prophet`) for native forecasting models.
* Combine Scikit-learn with Pandas for powerful time-based ML workflows.

