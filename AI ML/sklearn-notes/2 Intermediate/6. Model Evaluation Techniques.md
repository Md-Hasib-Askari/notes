## ðŸŸ¡ Intermediate Level

### 6. Model Evaluation Techniques

Evaluating a machine learning model is critical to ensure it performs well on unseen data. Scikit-learn offers several tools for model validation and performance metrics.

---

### ðŸ“Œ 1. Train-Test Split (Basic Evaluation)

Split data into training and testing sets:

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

---

### ðŸ“Œ 2. Cross-Validation

**K-Fold Cross Validation** splits data into *k* parts, trains on *k-1* parts, tests on the remaining, and repeats.

```python
from sklearn.model_selection import cross_val_score

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()

scores = cross_val_score(model, X, y, cv=5)
print(scores)
print("Average CV Score:", scores.mean())
```

---

### ðŸ“Œ 3. Classification Metrics

**Accuracy Score:**

```python
from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred)
```

**Precision, Recall, F1 Score:**

```python
from sklearn.metrics import precision_score, recall_score, f1_score

precision_score(y_test, y_pred, average='macro')
recall_score(y_test, y_pred, average='macro')
f1_score(y_test, y_pred, average='macro')
```

**Confusion Matrix:**

```python
from sklearn.metrics import confusion_matrix
confusion_matrix(y_test, y_pred)
```

**Classification Report (all-in-one):**

```python
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))
```

---

### ðŸ“Œ 4. ROC Curve & AUC (for binary classification)

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

y_prob = model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_prob)

plt.plot(fpr, tpr)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.show()

roc_auc_score(y_test, y_prob)
```

---

### ðŸ“Œ 5. Regression Metrics

```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

mean_squared_error(y_test, y_pred)
mean_absolute_error(y_test, y_pred)
r2_score(y_test, y_pred)
```

---

### ðŸ§  Pro Tip:

Use `cross_val_score()` with scoring options:

```python
cross_val_score(model, X, y, cv=5, scoring='f1_macro')
```
