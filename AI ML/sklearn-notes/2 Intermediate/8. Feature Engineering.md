## ðŸŸ¡ Intermediate Level

### 8. Feature Engineering

**Feature Engineering** is the process of selecting, transforming, or creating new features to improve model performance. Scikit-learn provides several tools to automate and streamline this process.

---

### ðŸ“Œ 1. Why Feature Engineering Matters

* Enhances model accuracy.
* Removes irrelevant or noisy features.
* Makes patterns more detectable to the model.
* Helps reduce overfitting.

---

### ðŸ“Œ 2. Feature Selection Techniques

#### âœ… Variance Threshold

Removes features with low variance (i.e., almost constant values).

```python
from sklearn.feature_selection import VarianceThreshold

selector = VarianceThreshold(threshold=0.1)
X_selected = selector.fit_transform(X)
```

---

#### âœ… SelectKBest

Selects the top *k* features based on a scoring function.

```python
from sklearn.feature_selection import SelectKBest, f_classif

selector = SelectKBest(score_func=f_classif, k=5)
X_selected = selector.fit_transform(X, y)
```

---

#### âœ… Recursive Feature Elimination (RFE)

Selects features by recursively removing least important ones.

```python
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
rfe = RFE(estimator=model, n_features_to_select=5)
X_selected = rfe.fit_transform(X, y)
```

---

### ðŸ“Œ 3. Feature Transformation Techniques

#### âœ… Polynomial Features

Create interaction and power terms from numerical features.

```python
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)
```

---

#### âœ… Binning (Discretization)

Convert continuous values into categorical bins.

```python
from sklearn.preprocessing import KBinsDiscretizer

kbins = KBinsDiscretizer(n_bins=3, encode='onehot-dense', strategy='uniform')
X_binned = kbins.fit_transform(X)
```

---

### ðŸ“Œ 4. Dimensionality Reduction

Used when there are too many features, or features are highly correlated.

#### âœ… Principal Component Analysis (PCA)

Transforms data into a lower-dimensional space while preserving variance.

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X_reduced = pca.fit_transform(X)
```

---

### ðŸ“Œ 5. Automated Pipelines for Feature Engineering

You can chain feature selection or transformation into a pipeline.

```python
from sklearn.pipeline import Pipeline

pipeline = Pipeline([
    ('poly', PolynomialFeatures(degree=2)),
    ('select', SelectKBest(k=5)),
    ('model', LogisticRegression())
])
pipeline.fit(X_train, y_train)
```
