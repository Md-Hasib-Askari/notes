## üü° Intermediate Level ‚Äì Step 6 (Part 3): **InfoGAN ‚Äì Learning Disentangled Representations**

### üéØ Goal:

Learn to build **InfoGAN**, which extends GANs to discover and control **interpretable latent features** (e.g., digit style, rotation, etc.) without labels.

---

## üß† What Is InfoGAN?

**InfoGAN** is an **unsupervised extension** of GANs.
It encourages the generator to learn **structured and meaningful latent factors** by maximizing the **mutual information** between:

* A **subset of latent code** (e.g., `c`)
* The **generated output** `G(z, c)`

---

## üîÅ Core Idea

> **Split the latent input** to the Generator into:

* `z`: noise (unstructured)
* `c`: code vector (structured, e.g., digit rotation, thickness, etc.)

Then:

* Maximize the **mutual information** between `c` and `G(z, c)`.
* Use a separate **Q-network** to predict `c` from generated images.

---

## üß© InfoGAN Architecture Components

| Component               | Role                                                                  |
| ----------------------- | --------------------------------------------------------------------- |
| `G(z, c)`               | Generator takes both noise and latent code                            |
| `D(x)`                  | Discriminator: real or fake                                           |
| `Q(x)`                  | Auxiliary network to **predict latent code `c`** from generated image |
| Mutual Information Loss | Encourages meaningful mapping from `c` to output                      |

---

## üìê Loss Functions

### 1. **Standard GAN loss**

Same as vanilla GAN (D vs G)

### 2. **Mutual Information loss**

We **maximize**:

$$
I(c; G(z, c))
$$

In practice, we use **variational lower bound** with a Q-network:

$$
\mathcal{L}_{info} = \mathbb{E}[\log Q(c|G(z, c))]
$$

### Final Generator Loss:

$$
\mathcal{L}_G = \text{GAN Loss} - \lambda \cdot \mathcal{L}_{info}
$$

---

## üîß Implementation Tips

* `z`: Random noise, e.g., 62-D
* `c`: Interpretable latent code:

  * Categorical (e.g., 10-digit class): one-hot or index
  * Continuous (e.g., rotation): Uniform(-1, 1)

### Example:

```python
z = torch.randn(batch_size, 62)
c_cat = F.one_hot(torch.randint(0, 10, (batch_size,)), num_classes=10).float()
c_cont = torch.rand(batch_size, 2) * 2 - 1  # [-1, 1]
input = torch.cat((z, c_cat, c_cont), dim=1)
```

---

## üì¶ Q-Network Architecture

* Shares parameters with Discriminator (until last few layers)
* Predicts `c` from fake image
* Outputs:

  * Logits for categorical `c_cat`
  * Mean & log-variance for continuous `c_cont`

---

## üìä Training Flow

1. Generator generates `x = G(z, c)`
2. Discriminator tries to distinguish real vs. fake
3. Q-network tries to **recover `c` from `G(z, c)`**
4. Mutual information loss added to Generator loss
5. Optimize:

   * D: normal GAN loss
   * G + Q: adversarial loss + mutual info loss

---

## üß™ Mini Project

* Use MNIST dataset
* Define:

  * `z`: 62-D noise
  * `c_cat`: 1 categorical variable (10 classes)
  * `c_cont`: 2 continuous variables
* After training:

  * Fix `z`, vary `c_cont` ‚Üí observe style/rotation change
  * Fix `c_cat` ‚Üí generate one class consistently

---

## ‚úÖ Summary

| Feature               | cGAN | InfoGAN |
| --------------------- | ---- | ------- |
| Uses labels           | ‚úÖ    | ‚ùå       |
| Controlled generation | ‚úÖ    | ‚úÖ       |
| Disentangled features | ‚ùå    | ‚úÖ       |
| Needs Q-network       | ‚ùå    | ‚úÖ       |
