
## üóÉÔ∏è 11. Databases & Data Pipelines ‚Äì Notes

### üìå Overview:

Databases and pipelines ensure that **data flows efficiently and reliably** through collection, transformation, storage, and retrieval‚Äîessential for production-grade AI systems.

---

### üßæ 11.1 SQL (PostgreSQL / MySQL)

#### ‚úÖ Why SQL?

* Structured data storage
* Fast querying with indexes
* Widely supported in analytics and ML pipelines

#### ‚úÖ Common SQL Operations:

```sql
SELECT * FROM patients WHERE age > 60;
INSERT INTO users (name, age) VALUES ('Hasib', 22);
UPDATE sales SET amount = 500 WHERE id = 1;
```

#### ‚úÖ Libraries:

* `psycopg2` / `sqlalchemy` for PostgreSQL
* `mysql-connector-python` for MySQL

---

### üì¶ 11.2 NoSQL (MongoDB)

#### ‚úÖ Why NoSQL?

* Flexible schemas (JSON-like)
* Ideal for unstructured/semi-structured data
* Good for logs, documents, user tracking

#### ‚úÖ MongoDB Example (PyMongo):

```python
from pymongo import MongoClient
client = MongoClient("mongodb://localhost:27017")
db = client["ml_app"]
db.users.insert_one({"name": "Hasib", "age": 22})
```

---

### üîÅ 11.3 Airflow / Prefect Basics

#### ‚úÖ Purpose:

* Automate, schedule, and monitor ML workflows

#### ‚úÖ Airflow:

* DAG (Directed Acyclic Graph) defines tasks & dependencies

```python
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
```

#### ‚úÖ Prefect:

* Python-native, simpler for beginners

```python
from prefect import flow, task

@task
def clean_data(): ...
@flow
def main_flow(): clean_data()
```

---

### üîÑ 11.4 ETL Pipelines

#### ‚úÖ ETL = Extract ‚Üí Transform ‚Üí Load

| Step      | Example Tool  | Description                      |
| --------- | ------------- | -------------------------------- |
| Extract   | Python, APIs  | Pull raw data from source        |
| Transform | Pandas, Spark | Clean/aggregate/feature-engineer |
| Load      | SQL, MongoDB  | Store into DB or data warehouse  |

#### ‚úÖ Key Concepts:

* **Batch vs Stream** processing
* **Orchestration**: Ensures the right order and scheduling
* **Monitoring**: Track data freshness, failures, etc.

