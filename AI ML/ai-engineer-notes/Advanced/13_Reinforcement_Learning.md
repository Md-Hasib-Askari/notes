
## ğŸ® 13. Reinforcement Learning â€“ Notes

### ğŸ“Œ Overview:

Reinforcement Learning (RL) is a paradigm where agents **learn by interacting** with an environment to maximize cumulative rewards over time. It's the foundation of **AlphaGo, robotics, and autonomous systems**.

---

### ğŸ§¾ 13.1 Markov Decision Processes (MDP)

#### âœ… Key Components:

* **S**: States (e.g., grid positions)
* **A**: Actions (e.g., move up/down)
* **P**: Transition probabilities $P(s' | s, a)$
* **R**: Rewards for state transitions
* **Î³**: Discount factor for future rewards

#### âœ… Bellman Equation:

$$
V(s) = \max_a \left[ R(s, a) + \gamma \sum_{s'} P(s'|s,a)V(s') \right]
$$

---

### ğŸ” 13.2 Q-Learning & Deep Q-Networks (DQN)

#### âœ… Q-Learning (Tabular):

```python
Q[s][a] = Q[s][a] + Î± * (r + Î³ * max(Q[sâ€™]) - Q[s][a])
```

#### âœ… DQN (Deep Q-Network):

* Uses a neural net to approximate Q-values
* Stabilized with **experience replay** and **target networks**

```python
Q(s, a) â‰ˆ NN(s)[a]
```

#### âœ… Frameworks:

* TensorFlow / PyTorch
* `stable-baselines3`

---

### ğŸ§  13.3 Policy Gradient Methods

#### âœ… Difference from Q-Learning:

* **Policy-based** methods directly learn Ï€(a|s)
* Suitable for **continuous action spaces**

#### âœ… REINFORCE Algorithm:

$$
\theta = \theta + \alpha \cdot \nabla_\theta \log \pi_\theta(a|s) \cdot G_t
$$

#### âœ… Advanced Variants:

* **Actor-Critic**
* **Proximal Policy Optimization (PPO)**
* **Trust Region Policy Optimization (TRPO)**

---

### ğŸ§ª 13.4 OpenAI Gym

#### âœ… A toolkit for training RL agents:

* Simulates environments: CartPole, MountainCar, Atari, etc.

```python
import gym
env = gym.make("CartPole-v1")
state = env.reset()
```

#### âœ… Common Workflow:

1. Initialize environment
2. Agent selects action
3. Environment returns new state + reward
4. Train policy/Q-values

