# Sentiment Analysis Dashboard

This project demonstrates how to build a real-time sentiment analysis dashboard for monitoring social media or customer feedback data.

## Project Overview

This dashboard will:
- Collect text data from various sources
- Analyze sentiment in real-time
- Visualize sentiment trends
- Allow filtering by time period, source, and keywords

## Implementation Steps

### 1. Data Collection

Set up data collection from a source like Twitter API:

```python
import tweepy

# Configure Twitter API credentials
consumer_key = "YOUR_CONSUMER_KEY"
consumer_secret = "YOUR_CONSUMER_SECRET"
access_token = "YOUR_ACCESS_TOKEN"
access_token_secret = "YOUR_ACCESS_SECRET"

# Authenticate to Twitter API
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tweepy.API(auth)

# Stream tweets in real-time based on keywords
class TweetListener(tweepy.StreamListener):
    def on_status(self, status):
        # Process and store tweet
        process_tweet(status.text)
        return True

# Create stream
tweet_listener = TweetListener()
stream = tweepy.Stream(auth=api.auth, listener=tweet_listener)
stream.filter(track=['keyword1', 'keyword2'], languages=['en'])
```

### 2. Sentiment Analysis Pipeline

Implement a robust sentiment analysis pipeline:

```python
import pandas as pd
from transformers import pipeline
from textblob import TextBlob
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Download NLTK resources
nltk.download('vader_lexicon')

# Initialize sentiment analyzers
transformer_analyzer = pipeline("sentiment-analysis")
vader_analyzer = SentimentIntensityAnalyzer()

def analyze_sentiment(text):
    # TextBlob analysis
    blob = TextBlob(text)
    textblob_score = blob.sentiment.polarity
    
    # VADER analysis
    vader_scores = vader_analyzer.polarity_scores(text)
    
    # Transformer-based analysis
    transformer_result = transformer_analyzer(text)[0]
    
    # Combine or select best result based on confidence
    # For this example, we'll use a weighted ensemble
    if transformer_result['score'] > 0.8:
        # High confidence from transformer model
        sentiment = transformer_result['label']
        score = transformer_result['score']
    else:
        # Combine rule-based and ML approaches
        compound_score = (textblob_score + vader_scores['compound']) / 2
        if compound_score > 0.05:
            sentiment = "POSITIVE"
            score = compound_score
        elif compound_score < -0.05:
            sentiment = "NEGATIVE"
            score = -compound_score
        else:
            sentiment = "NEUTRAL"
            score = 1 - abs(compound_score)
    
    return {
        "sentiment": sentiment,
        "score": score,
        "detail": {
            "textblob": textblob_score,
            "vader": vader_scores,
            "transformer": transformer_result
        }
    }
```

### 3. Database Storage

Store analyzed data in a database:

```python
import sqlite3
from datetime import datetime

def store_sentiment_data(text, source, sentiment_result):
    conn = sqlite3.connect('sentiment_dashboard.db')
    cursor = conn.cursor()
    
    # Create table if it doesn't exist
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS sentiment_data (
        id INTEGER PRIMARY KEY,
        text TEXT,
        source TEXT,
        sentiment TEXT,
        score REAL,
        timestamp DATETIME
    )
    ''')
    
    # Insert data
    cursor.execute('''
    INSERT INTO sentiment_data (text, source, sentiment, score, timestamp)
    VALUES (?, ?, ?, ?, ?)
    ''', (
        text, 
        source, 
        sentiment_result['sentiment'], 
        sentiment_result['score'],
        datetime.now()
    ))
    
    conn.commit()
    conn.close()
```

### 4. Dashboard with Streamlit

Create an interactive dashboard with Streamlit:

```python
import streamlit as st
import pandas as pd
import plotly.express as px
import sqlite3
from datetime import datetime, timedelta

st.title("Real-time Sentiment Analysis Dashboard")

# Date filter
st.sidebar.header("Filters")
date_range = st.sidebar.selectbox(
    "Time Period",
    ["Last Hour", "Today", "Last 7 Days", "Last 30 Days", "All Time"]
)

# Source filter
sources = ["Twitter", "Customer Reviews", "News Articles", "All Sources"]
selected_source = st.sidebar.multiselect("Data Source", sources, default="All Sources")

# Connect to database and query data
conn = sqlite3.connect('sentiment_dashboard.db')

# Build query based on filters
query = "SELECT * FROM sentiment_data WHERE 1=1"

# Apply date filter
if date_range != "All Time":
    if date_range == "Last Hour":
        time_threshold = datetime.now() - timedelta(hours=1)
    elif date_range == "Today":
        time_threshold = datetime.now().replace(hour=0, minute=0, second=0)
    elif date_range == "Last 7 Days":
        time_threshold = datetime.now() - timedelta(days=7)
    elif date_range == "Last 30 Days":
        time_threshold = datetime.now() - timedelta(days=30)
    
    query += f" AND timestamp >= '{time_threshold}'"

# Apply source filter
if "All Sources" not in selected_source:
    sources_str = ",".join([f"'{s}'" for s in selected_source])
    query += f" AND source IN ({sources_str})"

# Load data
df = pd.read_sql(query, conn)
conn.close()

# Display sentiment distribution
st.header("Sentiment Distribution")
fig = px.pie(df, names='sentiment', values='score', color='sentiment',
             color_discrete_map={'POSITIVE':'green', 'NEUTRAL':'gray', 'NEGATIVE':'red'})
st.plotly_chart(fig)

# Display sentiment over time
st.header("Sentiment Trends")
df['date'] = pd.to_datetime(df['timestamp'])
df['date'] = df['date'].dt.date
sentiment_by_date = df.groupby(['date', 'sentiment']).size().reset_index(name='count')
fig2 = px.line(sentiment_by_date, x='date', y='count', color='sentiment')
st.plotly_chart(fig2)

# Display recent data
st.header("Recent Data")
st.dataframe(df[['text', 'source', 'sentiment', 'score', 'timestamp']].tail(10))
```

## Deployment

Deploy the dashboard using Streamlit Cloud or Docker:

```bash
# Install required packages
pip install tweepy textblob nltk transformers streamlit plotly pandas

# Run the streamlit app
streamlit run dashboard.py
```

## Further Enhancements

- Add sentiment by keyword analysis
- Implement topic modeling to group text by themes
- Add user authentication for dashboard access
- Integrate email alerts for sudden sentiment shifts
- Create exportable reports in PDF or Excel format
