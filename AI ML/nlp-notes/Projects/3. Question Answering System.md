# Question-Answering System

This project demonstrates how to build a question-answering (QA) system that can extract answers from documents or knowledge bases.

## Project Overview

This QA system will:
- Process input documents to create a knowledge base
- Accept natural language questions
- Retrieve relevant context from documents
- Extract precise answers from the context
- Handle both factoid and open-ended questions

## Implementation Steps

### 1. Document Processing and Indexing

Set up document processing and indexing:

```python
import os
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import pickle
import nltk
from nltk.tokenize import sent_tokenize

# Download NLTK resources
nltk.download('punkt')

class DocumentProcessor:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.model = SentenceTransformer(model_name)
        self.faiss_index = None
        self.sentences = []
        self.document_mapping = {}
    
    def process_documents(self, documents_dir):
        """Process and index all documents in the directory"""
        doc_id = 0
        for filename in os.listdir(documents_dir):
            if filename.endswith('.txt'):
                with open(os.path.join(documents_dir, filename), 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Split into sentences
                sentences = sent_tokenize(content)
                
                # Map sentences to document
                for sent_id, sentence in enumerate(sentences):
                    self.sentences.append(sentence)
                    self.document_mapping[len(self.sentences) - 1] = {
                        'doc_id': doc_id,
                        'filename': filename,
                        'sentence_id': sent_id
                    }
                
                doc_id += 1
    
    def build_index(self):
        """Build FAISS index for fast similarity search"""
        if not self.sentences:
            raise ValueError("No documents processed yet")
        
        # Encode all sentences
        embeddings = self.model.encode(self.sentences)
        
        # Create FAISS index
        dimension = embeddings.shape[1]
        self.faiss_index = faiss.IndexFlatL2(dimension)
        self.faiss_index.add(np.array(embeddings).astype('float32'))
    
    def save_index(self, filepath):
        """Save index and metadata to disk"""
        faiss.write_index(self.faiss_index, f"{filepath}.index")
        
        with open(f"{filepath}.pickle", 'wb') as f:
            pickle.dump({
                'sentences': self.sentences,
                'document_mapping': self.document_mapping
            }, f)
    
    @classmethod
    def load_index(cls, filepath):
        """Load index and metadata from disk"""
        processor = cls()
        processor.faiss_index = faiss.read_index(f"{filepath}.index")
        
        with open(f"{filepath}.pickle", 'rb') as f:
            data = pickle.load(f)
            processor.sentences = data['sentences']
            processor.document_mapping = data['document_mapping']
        
        return processor

# Usage
processor = DocumentProcessor()
processor.process_documents("./documents")
processor.build_index()
processor.save_index("./qa_system")
```

### 2. Question Processing and Retrieval

Implement question processing and context retrieval:

```python
from transformers import AutoTokenizer, AutoModelForQuestionAnswering
import torch

class QASystem:
    def __init__(self, index_path, qa_model_name="deepset/roberta-base-squad2"):
        # Load document processor and index
        self.processor = DocumentProcessor.load_index(index_path)
        
        # Load QA model
        self.tokenizer = AutoTokenizer.from_pretrained(qa_model_name)
        self.model = AutoModelForQuestionAnswering.from_pretrained(qa_model_name)
    
    def retrieve_context(self, question, top_k=5):
        """Retrieve most relevant sentences for the question"""
        # Encode question
        question_embedding = self.processor.model.encode([question])[0].reshape(1, -1)
        
        # Search in FAISS index
        distances, indices = self.processor.faiss_index.search(
            np.array(question_embedding).astype('float32'), top_k
        )
        
        # Get relevant sentences
        relevant_sentences = [self.processor.sentences[idx] for idx in indices[0]]
        
        # Concatenate sentences to form context
        context = " ".join(relevant_sentences)
        
        return context, indices[0]
    
    def answer_question(self, question, context=None):
        """Extract answer from context"""
        # If context not provided, retrieve it
        if context is None:
            context, indices = self.retrieve_context(question)
        
        # Tokenize
        inputs = self.tokenizer(
            question, context, 
            return_tensors="pt", 
            max_length=512, 
            truncation=True,
            stride=128,
            return_overflowing_tokens=True
        )
        
        # Get predictions
        with torch.no_grad():
            outputs = self.model(**inputs)
        
        # Get answer
        answer_start = torch.argmax(outputs.start_logits)
        answer_end = torch.argmax(outputs.end_logits) + 1
        
        answer = self.tokenizer.convert_tokens_to_string(
            self.tokenizer.convert_ids_to_tokens(
                inputs.input_ids[0][answer_start:answer_end]
            )
        )
        
        return {
            'answer': answer,
            'context': context
        }

# Usage
qa_system = QASystem("./qa_system")
result = qa_system.answer_question("Who invented the light bulb?")
print(f"Answer: {result['answer']}")
print(f"Context: {result['context']}")
```

### 3. Creating a Simple Web Interface

Build a web interface with Flask:

```python
from flask import Flask, request, jsonify, render_template

app = Flask(__name__)
qa_system = QASystem("./qa_system")

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/answer', methods=['POST'])
def get_answer():
    data = request.json
    question = data.get('question')
    
    if not question:
        return jsonify({'error': 'No question provided'}), 400
    
    result = qa_system.answer_question(question)
    
    return jsonify({
        'answer': result['answer'],
        'context': result['context']
    })

if __name__ == '__main__':
    app.run(debug=True)
```

HTML template (`templates/index.html`):

```html
<!DOCTYPE html>
<html>
<head>
    <title>Question Answering System</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 0; padding: 20px; }
        .container { max-width: 800px; margin: 0 auto; }
        .question-form { margin-bottom: 20px; }
        input[type="text"] { width: 70%; padding: 10px; }
        button { padding: 10px 15px; background: #4285f4; color: white; border: none; }
        .result { border: 1px solid #ddd; padding: 15px; border-radius: 5px; }
        .answer { font-weight: bold; margin-bottom: 10px; }
        .context { font-size: 0.9em; color: #555; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Question Answering System</h1>
        <div class="question-form">
            <input type="text" id="question" placeholder="Ask a question...">
            <button onclick="getAnswer()">Ask</button>
        </div>
        <div class="result" id="result" style="display: none;">
            <h3>Answer:</h3>
            <div class="answer" id="answer"></div>
            <h3>Context:</h3>
            <div class="context" id="context"></div>
        </div>
    </div>

    <script>
        async function getAnswer() {
            const question = document.getElementById('question').value;
            if (!question) return;

            document.getElementById('result').style.display = 'none';
            
            try {
                const response = await fetch('/answer', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ question })
                });
                
                const result = await response.json();
                
                document.getElementById('answer').textContent = result.answer;
                document.getElementById('context').textContent = result.context;
                document.getElementById('result').style.display = 'block';
            } catch (error) {
                console.error('Error:', error);
            }
        }
    </script>
</body>
</html>
```

### 4. Evaluation and Improvement

Evaluate and improve system performance:

```python
def evaluate_qa_system(qa_system, eval_data):
    """Evaluate QA system performance"""
    results = {
        'exact_match': 0,
        'f1_score': 0,
        'total': len(eval_data)
    }
    
    for item in eval_data:
        question = item['question']
        ground_truth = item['answer']
        
        # Get system prediction
        prediction = qa_system.answer_question(question)
        predicted_answer = prediction['answer']
        
        # Calculate metrics
        exact_match = calculate_exact_match(predicted_answer, ground_truth)
        f1 = calculate_f1_score(predicted_answer, ground_truth)
        
        results['exact_match'] += exact_match
        results['f1_score'] += f1
    
    # Calculate averages
    results['exact_match'] = results['exact_match'] / results['total']
    results['f1_score'] = results['f1_score'] / results['total']
    
    return results
```

## Further Enhancements

- Implement multi-hop reasoning for complex questions
- Add capability to handle multiple knowledge sources
- Incorporate knowledge graphs for structured data
- Implement query reformulation for improved retrieval
- Add confidence scores for answers
