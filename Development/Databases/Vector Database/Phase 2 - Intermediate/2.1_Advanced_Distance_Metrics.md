# 2.1 Advanced Distance Metrics and Spaces

## Metric Spaces

A metric space is a set with a notion of distance between its elements.

### Properties of Metric Spaces

For a distance function d to define a metric space, it must satisfy:
- **Non-negativity**: d(x,y) ≥ 0
- **Identity**: d(x,y) = 0 if and only if x = y
- **Symmetry**: d(x,y) = d(y,x)
- **Triangle Inequality**: d(x,z) ≤ d(x,y) + d(y,z)

These properties ensure mathematical consistency in distance calculations and enable efficient indexing algorithms.

### Non-metric Similarities

Some similarity measures don't satisfy all metric space requirements but are still useful:

- **Asymmetric Measures**: d(x,y) ≠ d(y,x)
  - Example: KL-divergence for probability distributions
  - Use cases: Information retrieval, document classification

- **Semi-metrics**: Violate triangle inequality
  - Example: Cosine distance (1-cosine similarity)
  - Use cases: Text similarity, recommendation systems

- **Pseudo-metrics**: Allow d(x,y) = 0 for x ≠ y
  - Example: Distance between word forms ("run" vs "running")
  - Use cases: Semantic matching, fuzzy search

### Normalized vs Unnormalized Vectors

- **Unnormalized Vectors**:
  - Preserve magnitude information
  - Better when absolute values matter
  - Euclidean distance works well

- **Normalized Vectors** (unit vectors):
  - Scale to consistent magnitude (usually 1)
  - Only direction information remains
  - Cosine similarity becomes equivalent to dot product
  - Reduces effects of document length or feature scale
  - Standard practice in text retrieval and embeddings

## Specialized Distances

### Jaccard Similarity

- **Formula**: J(A,B) = |A∩B| / |A∪B|
- **Properties**:
  - Range: [0,1]
  - Measures set overlap
  - Ignores element values, only considers presence/absence
- **Applications**:
  - Document deduplication
  - Collaborative filtering
  - Sparse binary data
  - MinHash technique for approximation

### Pearson Correlation

- **Formula**: ρ(x,y) = cov(x,y) / (σₓσᵧ)
- **Properties**:
  - Range: [-1,1]
  - Measures linear relationship
  - Invariant to scaling and shifting
- **Applications**:
  - Feature correlation analysis
  - Recommendation systems
  - Time series similarity
  - When feature means should be normalized

### Mahalanobis Distance

- **Formula**: d(x,y) = √((x-y)ᵀS⁻¹(x-y)) where S is covariance matrix
- **Properties**:
  - Accounts for correlation between features
  - Scale-invariant
  - Generalizes Euclidean distance
- **Applications**:
  - Anomaly detection
  - Multivariate analysis
  - When features have different scales and correlations
  - Face recognition and biometrics

### Custom Distance Functions

- **Domain-specific distances**:
  - Edit distance for strings (Levenshtein)
  - Earth Mover's Distance for distributions
  - Dynamic Time Warping for time series

- **Learning-based distances**:
  - Siamese networks
  - Contrastive loss functions
  - Triplet loss architectures

- **Implementation considerations**:
  - Computational complexity
  - Differentiability
  - Compatibility with indexing algorithms
