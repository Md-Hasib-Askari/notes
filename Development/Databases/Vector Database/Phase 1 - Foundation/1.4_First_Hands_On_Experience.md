# 1.4 First Hands-On Experience with Vector Databases

## Tools to Start With

### Pinecone (Managed Service)

- **Overview**:
  - Fully managed vector database service
  - Serverless deployment option
  - Optimized for production-ready workloads

- **Key Features**:
  - Multiple distance metrics (cosine, Euclidean, dot product)
  - Metadata filtering
  - Horizontal scaling
  - Managed index updates

- **Getting Started**:
  - Sign up for free tier
  - Create index with desired parameters
  - Use Python client library for operations
  - Simple API with upsert, query, delete operations

### Weaviate (Open Source)

- **Overview**:
  - Open-source vector database
  - GraphQL and REST APIs
  - Self-hosted or cloud options

- **Key Features**:
  - Multi-modal data support
  - Class-based schema
  - Built-in vectorizers
  - Modular architecture with plugins

- **Getting Started**:
  - Docker-based deployment
  - Define schema with classes and properties
  - Use client libraries (Python, JavaScript, Go)
  - GraphQL-based queries

### Chroma (Lightweight Option)

- **Overview**:
  - Embedded vector database
  - Python-native
  - Focused on simplicity and ease of use

- **Key Features**:
  - Persistent or in-memory storage
  - Document metadata
  - Collection-based organization
  - Direct integration with embedding models

- **Getting Started**:
  - `pip install chromadb`
  - Create collections
  - Add documents with embeddings
  - Query with vector and optional filters

### Simple Implementations with NumPy

- **Basic Vector Storage**:
```python
import numpy as np

# Create a simple vector store
vectors = np.random.rand(1000, 128)  # 1000 vectors of dimension 128
metadata = [{"id": i, "text": f"Document {i}"} for i in range(1000)]

# Simple cosine similarity search
def cosine_similarity(query_vector, vectors):
    dot_product = np.dot(vectors, query_vector)
    query_norm = np.linalg.norm(query_vector)
    vectors_norm = np.linalg.norm(vectors, axis=1)
    return dot_product / (query_norm * vectors_norm)

# Search example
query = np.random.rand(128)
similarities = cosine_similarity(query, vectors)
top_k_indices = np.argsort(similarities)[-5:][::-1]  # Top 5 results
results = [metadata[i] for i in top_k_indices]
```

## Basic Operations

### Creating Vectors

- **From Text**:
  - Using embedding models (transformers, sentence-transformers)
  - Example:
    ```python
    from sentence_transformers import SentenceTransformer
    model = SentenceTransformer('all-MiniLM-L6-v2')
    documents = ["Vector databases store embeddings", "Similarity search is powerful"]
    embeddings = model.encode(documents)
    ```

- **From Images**:
  - Using CNN or vision transformer models
  - Example with CLIP:
    ```python
    import torch
    from PIL import Image
    from transformers import CLIPProcessor, CLIPModel
    
    model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
    processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
    image = Image.open("example.jpg")
    inputs = processor(images=image, return_tensors="pt")
    image_features = model.get_image_features(**inputs)
    ```

### Inserting Data

- **Pinecone Example**:
  ```python
  import pinecone
  
  pinecone.init(api_key="your-api-key", environment="your-environment")
  index = pinecone.Index("example-index")
  
  # Upsert vectors
  vectors_to_upsert = [
      {"id": "vec1", "values": [0.1, 0.2, 0.3], "metadata": {"text": "Example 1"}},
      {"id": "vec2", "values": [0.4, 0.5, 0.6], "metadata": {"text": "Example 2"}}
  ]
  index.upsert(vectors=vectors_to_upsert)
  ```

- **Chroma Example**:
  ```python
  import chromadb
  
  client = chromadb.Client()
  collection = client.create_collection("example_collection")
  
  collection.add(
      embeddings=[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]],
      documents=["Example 1", "Example 2"],
      ids=["id1", "id2"]
  )
  ```

### Performing Similarity Searches

- **Pinecone Example**:
  ```python
  query_vector = [0.2, 0.3, 0.4]
  results = index.query(
      vector=query_vector,
      top_k=5,
      include_metadata=True
  )
  ```

- **Weaviate Example**:
  ```python
  import weaviate
  client = weaviate.Client("http://localhost:8080")
  
  result = (
    client.query
    .get("Document", ["text", "category"])
    .with_near_vector({
        "vector": query_vector
    })
    .with_limit(5)
    .do()
  )
  ```

### Retrieving Results

- **Processing Query Results**:
  ```python
  # Pinecone results processing
  for match in results["matches"]:
      print(f"ID: {match['id']}")
      print(f"Score: {match['score']}")
      print(f"Metadata: {match['metadata']}")
  
  # Filtering results by threshold
  filtered_results = [match for match in results["matches"] if match["score"] > 0.8]
  ```

- **Combining with Metadata Filters**:
  ```python
  # Pinecone with metadata filter
  results = index.query(
      vector=query_vector,
      top_k=10,
      include_metadata=True,
      filter={"category": {"$in": ["news", "article"]}}
  )
  
  # Chroma with metadata filter
  results = collection.query(
      query_embeddings=[query_vector],
      n_results=10,
      where={"category": "news"}
  )
  ```
