# 5.3 Advanced Debugging and Troubleshooting

## Learning Objectives
By the end of this module, you will:
- Master advanced debugging techniques for pywin32 applications
- Implement comprehensive troubleshooting strategies for Windows automation
- Use professional debugging tools and techniques for complex issues
- Develop systematic approaches to performance analysis and optimization
- Create robust diagnostic and monitoring systems for production environments

## Module Overview

This module covers expert-level debugging and troubleshooting techniques for pywin32 applications. You'll learn to diagnose complex issues, analyze performance bottlenecks, implement monitoring systems, and create tools for maintaining enterprise-grade Windows automation solutions.

Advanced debugging goes beyond simple print statements and basic error handling. It involves understanding system internals, using sophisticated tools, and developing systematic approaches to problem resolution.

## Key Topics

### 1. Advanced Debugging Techniques

#### 1.1 Python Debugging Integration

**Enhanced Debugging with pdb and IDE Integration**
```python
import pdb
import sys
import traceback
import threading
import time
import win32api
import win32con
import win32gui
import win32process

class AdvancedDebugger:
    """Advanced debugging utilities for pywin32 applications"""
    
    def __init__(self):
        self.debug_enabled = True
        self.trace_calls = False
        self.call_stack = []
        self.performance_data = {}
        self.debug_log = []
        
    def enable_comprehensive_tracing(self):
        """Enable comprehensive function call tracing"""
        def trace_calls(frame, event, arg):
            if not self.trace_calls:
                return
                
            if event == 'call':
                func_name = frame.f_code.co_name
                filename = frame.f_code.co_filename
                line_number = frame.f_lineno
                
                # Track pywin32 calls specifically
                if 'win32' in filename.lower():
                    call_info = {
                        'function': func_name,
                        'file': filename,
                        'line': line_number,
                        'timestamp': time.time(),
                        'thread': threading.get_ident(),
                        'locals': dict(frame.f_locals)
                    }
                    self.call_stack.append(call_info)
                    self.debug_log.append(f"CALL: {func_name} at {filename}:{line_number}")
                    
            elif event == 'return':
                if self.call_stack and 'win32' in frame.f_code.co_filename.lower():
                    call_info = self.call_stack.pop()
                    duration = time.time() - call_info['timestamp']
                    self.debug_log.append(f"RETURN: {call_info['function']} (duration: {duration:.4f}s)")
                    
                    # Track performance
                    func_name = call_info['function']
                    if func_name not in self.performance_data:
                        self.performance_data[func_name] = []
                    self.performance_data[func_name].append(duration)
                    
            return trace_calls
        
        sys.settrace(trace_calls)
        self.trace_calls = True
    
    def disable_tracing(self):
        """Disable function call tracing"""
        self.trace_calls = False
        sys.settrace(None)
    
    def debug_windows_api_call(self, api_function, *args, **kwargs):
        """Debug wrapper for Windows API calls"""
        func_name = getattr(api_function, '__name__', str(api_function))
        
        try:
            self.debug_log.append(f"API CALL: {func_name} with args: {args}, kwargs: {kwargs}")
            
            start_time = time.time()
            result = api_function(*args, **kwargs)
            end_time = time.time()
            
            duration = end_time - start_time
            self.debug_log.append(f"API SUCCESS: {func_name} returned {result} (duration: {duration:.4f}s)")
            
            return result
            
        except Exception as e:
            error_info = {
                'function': func_name,
                'args': args,
                'kwargs': kwargs,
                'error': str(e),
                'error_type': type(e).__name__,
                'traceback': traceback.format_exc()
            }
            
            self.debug_log.append(f"API ERROR: {func_name} failed with {type(e).__name__}: {e}")
            self._analyze_windows_error(e)
            
            raise
    
    def _analyze_windows_error(self, error):
        """Analyze Windows-specific errors"""
        try:
            if hasattr(error, 'winerror'):
                error_code = error.winerror
                error_message = win32api.FormatMessage(error_code)
                
                self.debug_log.append(f"Windows Error Code: {error_code}")
                self.debug_log.append(f"Windows Error Message: {error_message}")
                
                # Common error analysis
                common_errors = {
                    2: "File not found - Check file paths and existence",
                    5: "Access denied - Check permissions and privileges",
                    6: "Invalid handle - Check object lifecycle",
                    87: "Invalid parameter - Validate input parameters",
                    997: "Overlapped I/O operation in progress",
                    1004: "Invalid flags - Check API flag combinations"
                }
                
                if error_code in common_errors:
                    self.debug_log.append(f"Common Cause: {common_errors[error_code]}")
                    
        except Exception as analysis_error:
            self.debug_log.append(f"Error analysis failed: {analysis_error}")
    
    def debug_com_object(self, com_object):
        """Debug COM object details"""
        debug_info = {
            'object_type': type(com_object).__name__,
            'available_methods': [],
            'available_properties': [],
            'com_interface_info': {}
        }
        
        try:
            # Get available methods and properties
            if hasattr(com_object, '_oleobj_'):
                ole_obj = com_object._oleobj_
                
                # Get type information
                try:
                    type_info = ole_obj.GetTypeInfo(0)
                    type_attr = type_info.GetTypeAttr()
                    
                    debug_info['com_interface_info'] = {
                        'guid': str(type_attr.guid),
                        'version': f"{type_attr.wMajorVerNum}.{type_attr.wMinorVerNum}",
                        'functions': type_attr.cFuncs,
                        'variables': type_attr.cVars
                    }
                    
                    # Get function information
                    for i in range(type_attr.cFuncs):
                        func_desc = type_info.GetFuncDesc(i)
                        names = type_info.GetNames(func_desc.memid)
                        if names:
                            debug_info['available_methods'].append(names[0])
                    
                    # Get variable information
                    for i in range(type_attr.cVars):
                        var_desc = type_info.GetVarDesc(i)
                        names = type_info.GetNames(var_desc.memid)
                        if names:
                            debug_info['available_properties'].append(names[0])
                            
                except Exception as type_error:
                    debug_info['type_info_error'] = str(type_error)
            
            # Try to get basic object info
            try:
                debug_info['string_representation'] = str(com_object)
            except:
                debug_info['string_representation'] = 'Not available'
            
            self.debug_log.append(f"COM Object Debug Info: {debug_info}")
            return debug_info
            
        except Exception as e:
            error_info = f"COM object debugging failed: {e}"
            self.debug_log.append(error_info)
            return {'error': error_info}
    
    def get_performance_report(self):
        """Get performance analysis report"""
        report = {
            'total_calls': sum(len(calls) for calls in self.performance_data.values()),
            'function_stats': {}
        }
        
        for func_name, durations in self.performance_data.items():
            if durations:
                report['function_stats'][func_name] = {
                    'call_count': len(durations),
                    'total_time': sum(durations),
                    'average_time': sum(durations) / len(durations),
                    'min_time': min(durations),
                    'max_time': max(durations),
                    'slowest_calls': sorted(durations, reverse=True)[:5]
                }
        
        return report
    
    def save_debug_session(self, filename):
        """Save debug session to file"""
        import json
        
        session_data = {
            'debug_log': self.debug_log,
            'performance_data': self.performance_data,
            'call_stack_snapshot': self.call_stack,
            'session_timestamp': time.time()
        }
        
        with open(filename, 'w') as f:
            json.dump(session_data, f, indent=2, default=str)

# Example usage
def debug_excel_automation():
    """Example of debugging Excel automation"""
    debugger = AdvancedDebugger()
    debugger.enable_comprehensive_tracing()
    
    try:
        import win32com.client
        
        # Debug COM object creation
        excel = debugger.debug_windows_api_call(win32com.client.Dispatch, 'Excel.Application')
        debugger.debug_com_object(excel)
        
        # Debug property access
        excel.Visible = True
        
        # Debug method calls
        workbook = debugger.debug_windows_api_call(excel.Workbooks.Add)
        worksheet = workbook.ActiveSheet
        
        # Debug data operations
        worksheet.Cells(1, 1).Value = "Test Data"
        
        # Get performance report
        performance_report = debugger.get_performance_report()
        print("Performance Report:", performance_report)
        
    except Exception as e:
        print(f"Error during debugging: {e}")
    finally:
        debugger.disable_tracing()
        debugger.save_debug_session('debug_session.json')
```

#### 1.2 Memory and Resource Debugging

**Memory Analysis and Leak Detection**
```python
import gc
import psutil
import tracemalloc
import weakref
import threading
from collections import defaultdict

class MemoryDebugger:
    """Advanced memory debugging for pywin32 applications"""
    
    def __init__(self):
        self.snapshots = []
        self.object_tracking = defaultdict(list)
        self.com_objects = weakref.WeakSet()
        self.resource_tracking = {}
        self.baseline_memory = None
        
    def start_memory_tracking(self):
        """Start comprehensive memory tracking"""
        tracemalloc.start()
        self.baseline_memory = self.get_memory_info()
        print(f"Memory tracking started. Baseline: {self.baseline_memory}")
    
    def take_memory_snapshot(self, label=""):
        """Take memory snapshot for comparison"""
        if not tracemalloc.is_tracing():
            print("Memory tracking not started")
            return None
        
        snapshot = tracemalloc.take_snapshot()
        memory_info = self.get_memory_info()
        
        snapshot_data = {
            'label': label,
            'timestamp': time.time(),
            'snapshot': snapshot,
            'memory_info': memory_info,
            'object_counts': self._get_object_counts()
        }
        
        self.snapshots.append(snapshot_data)
        return snapshot_data
    
    def compare_snapshots(self, snapshot1_index=0, snapshot2_index=-1):
        """Compare two memory snapshots"""
        if len(self.snapshots) < 2:
            print("Need at least 2 snapshots for comparison")
            return None
        
        snap1 = self.snapshots[snapshot1_index]
        snap2 = self.snapshots[snapshot2_index]
        
        # Compare tracemalloc snapshots
        top_stats = snap2['snapshot'].compare_to(snap1['snapshot'], 'lineno')
        
        print(f"\nMemory comparison: {snap1['label']} -> {snap2['label']}")
        print(f"Memory change: {snap2['memory_info']['rss'] - snap1['memory_info']['rss']:,} bytes")
        
        print("\nTop 10 memory allocations:")
        for index, stat in enumerate(top_stats[:10], 1):
            print(f"{index:2d}. {stat}")
        
        # Compare object counts
        obj_diff = {}
        for obj_type, count2 in snap2['object_counts'].items():
            count1 = snap1['object_counts'].get(obj_type, 0)
            if count2 != count1:
                obj_diff[obj_type] = count2 - count1
        
        if obj_diff:
            print("\nObject count changes:")
            for obj_type, diff in sorted(obj_diff.items(), key=lambda x: abs(x[1]), reverse=True):
                print(f"  {obj_type}: {diff:+d}")
        
        return {
            'memory_diff': snap2['memory_info']['rss'] - snap1['memory_info']['rss'],
            'top_allocations': top_stats[:10],
            'object_diff': obj_diff
        }
    
    def track_com_object(self, com_object, description=""):
        """Track COM object for leak detection"""
        self.com_objects.add(com_object)
        
        # Store additional info
        obj_id = id(com_object)
        self.object_tracking[obj_id] = {
            'description': description,
            'created_at': time.time(),
            'traceback': traceback.format_stack(),
            'type': type(com_object).__name__
        }
        
        return com_object
    
    def get_memory_info(self):
        """Get current memory usage information"""
        process = psutil.Process()
        memory_info = process.memory_info()
        
        return {
            'rss': memory_info.rss,  # Resident Set Size
            'vms': memory_info.vms,  # Virtual Memory Size
            'percent': process.memory_percent(),
            'available': psutil.virtual_memory().available
        }
    
    def _get_object_counts(self):
        """Get counts of different object types"""
        object_counts = defaultdict(int)
        
        for obj in gc.get_objects():
            obj_type = type(obj).__name__
            object_counts[obj_type] += 1
        
        return dict(object_counts)
    
    def detect_memory_leaks(self):
        """Detect potential memory leaks"""
        leaks = []
        
        # Check for unreferenced COM objects
        live_com_objects = len(self.com_objects)
        if live_com_objects > 0:
            leaks.append({
                'type': 'COM Objects',
                'count': live_com_objects,
                'description': f"{live_com_objects} COM objects still referenced"
            })
        
        # Check for circular references
        gc.collect()
        unreachable = gc.garbage
        if unreachable:
            leaks.append({
                'type': 'Circular References',
                'count': len(unreachable),
                'objects': unreachable[:5]  # Show first 5
            })
        
        # Check for growing object types
        if len(self.snapshots) >= 2:
            recent_snapshot = self.snapshots[-1]
            baseline_snapshot = self.snapshots[0]
            
            for obj_type, current_count in recent_snapshot['object_counts'].items():
                baseline_count = baseline_snapshot['object_counts'].get(obj_type, 0)
                growth = current_count - baseline_count
                
                # Flag significant growth
                if growth > 100 and growth > baseline_count * 0.5:
                    leaks.append({
                        'type': f'Growing Objects: {obj_type}',
                        'count': growth,
                        'description': f"Object count grew from {baseline_count} to {current_count}"
                    })
        
        return leaks
    
    def generate_memory_report(self):
        """Generate comprehensive memory report"""
        current_memory = self.get_memory_info()
        memory_growth = 0
        
        if self.baseline_memory:
            memory_growth = current_memory['rss'] - self.baseline_memory['rss']
        
        report = {
            'current_memory': current_memory,
            'baseline_memory': self.baseline_memory,
            'memory_growth': memory_growth,
            'com_objects_tracked': len(self.com_objects),
            'snapshots_taken': len(self.snapshots),
            'potential_leaks': self.detect_memory_leaks()
        }
        
        return report

# Resource leak detection
class ResourceTracker:
    """Track system resources for leak detection"""
    
    def __init__(self):
        self.handles = {}
        self.files = {}
        self.registry_keys = {}
        
    def track_handle(self, handle, description=""):
        """Track Windows handle"""
        handle_id = int(handle) if handle else None
        if handle_id:
            self.handles[handle_id] = {
                'description': description,
                'created_at': time.time(),
                'stack': traceback.format_stack()
            }
    
    def untrack_handle(self, handle):
        """Remove handle from tracking"""
        handle_id = int(handle) if handle else None
        if handle_id in self.handles:
            del self.handles[handle_id]
    
    def get_leaked_resources(self):
        """Get list of potentially leaked resources"""
        leaked_resources = []
        
        # Check for old handles
        current_time = time.time()
        for handle_id, info in self.handles.items():
            age = current_time - info['created_at']
            if age > 300:  # 5 minutes
                leaked_resources.append({
                    'type': 'Handle',
                    'id': handle_id,
                    'age': age,
                    'description': info['description']
                })
        
        return leaked_resources

# Example usage
def debug_memory_intensive_operation():
    """Example of memory debugging for intensive operations"""
    debugger = MemoryDebugger()
    debugger.start_memory_tracking()
    
    # Take baseline snapshot
    debugger.take_memory_snapshot("Baseline")
    
    try:
        import win32com.client
        
        # Create multiple Excel instances to simulate memory issues
        excel_instances = []
        for i in range(5):
            excel = win32com.client.Dispatch('Excel.Application')
            excel = debugger.track_com_object(excel, f"Excel instance {i}")
            excel_instances.append(excel)
            
            # Create workbooks
            for j in range(3):
                workbook = excel.Workbooks.Add()
                # Don't close workbooks to simulate leak
        
        # Take snapshot after operations
        debugger.take_memory_snapshot("After Excel operations")
        
        # Clean up some objects
        for excel in excel_instances[:2]:
            excel.Quit()
        
        # Take final snapshot
        debugger.take_memory_snapshot("After partial cleanup")
        
        # Analyze results
        comparison = debugger.compare_snapshots(0, -1)
        memory_report = debugger.generate_memory_report()
        
        print("\nMemory Report:")
        print(f"Memory growth: {memory_report['memory_growth']:,} bytes")
        print(f"Potential leaks found: {len(memory_report['potential_leaks'])}")
        
        for leak in memory_report['potential_leaks']:
            print(f"  - {leak['type']}: {leak.get('count', 'N/A')} - {leak.get('description', '')}")
    
    except Exception as e:
        print(f"Error during memory debugging: {e}")
    
    finally:
        # Force cleanup
        gc.collect()
```

### 2. Performance Analysis and Optimization

#### 2.1 Performance Profiling

**Comprehensive Performance Analysis**
```python
import cProfile
import pstats
import functools
import time
import threading
from contextlib import contextmanager

class PerformanceProfiler:
    """Advanced performance profiling for pywin32 applications"""
    
    def __init__(self):
        self.profiles = {}
        self.timings = defaultdict(list)
        self.call_counts = defaultdict(int)
        self.active_timers = {}
        
    @contextmanager
    def profile_context(self, name):
        """Context manager for profiling code blocks"""
        profiler = cProfile.Profile()
        start_time = time.perf_counter()
        
        profiler.enable()
        try:
            yield
        finally:
            profiler.disable()
            end_time = time.perf_counter()
            
            self.profiles[name] = profiler
            self.timings[name].append(end_time - start_time)
    
    def profile_function(self, func):
        """Decorator for profiling functions"""
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            with self.profile_context(func.__name__):
                return func(*args, **kwargs)
        return wrapper
    
    def time_function(self, func):
        """Decorator for timing functions"""
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.perf_counter()
            try:
                result = func(*args, **kwargs)
                return result
            finally:
                end_time = time.perf_counter()
                duration = end_time - start_time
                self.timings[func.__name__].append(duration)
                self.call_counts[func.__name__] += 1
        return wrapper
    
    def start_timer(self, name):
        """Start a named timer"""
        self.active_timers[name] = time.perf_counter()
    
    def stop_timer(self, name):
        """Stop a named timer and record duration"""
        if name in self.active_timers:
            duration = time.perf_counter() - self.active_timers[name]
            self.timings[name].append(duration)
            del self.active_timers[name]
            return duration
        return None
    
    def get_profile_stats(self, profile_name, sort_by='cumulative'):
        """Get statistics for a specific profile"""
        if profile_name not in self.profiles:
            return None
        
        profiler = self.profiles[profile_name]
        stats = pstats.Stats(profiler)
        stats.sort_stats(sort_by)
        
        return stats
    
    def get_timing_summary(self):
        """Get summary of all timing data"""
        summary = {}
        
        for name, times in self.timings.items():
            if times:
                summary[name] = {
                    'count': len(times),
                    'total': sum(times),
                    'average': sum(times) / len(times),
                    'min': min(times),
                    'max': max(times),
                    'std_dev': self._calculate_std_dev(times)
                }
        
        return summary
    
    def _calculate_std_dev(self, values):
        """Calculate standard deviation"""
        if len(values) < 2:
            return 0
        
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / (len(values) - 1)
        return variance ** 0.5
    
    def identify_bottlenecks(self, threshold_seconds=0.1):
        """Identify performance bottlenecks"""
        bottlenecks = []
        summary = self.get_timing_summary()
        
        for name, stats in summary.items():
            if stats['average'] > threshold_seconds:
                bottlenecks.append({
                    'function': name,
                    'average_time': stats['average'],
                    'total_time': stats['total'],
                    'call_count': stats['count'],
                    'severity': 'high' if stats['average'] > threshold_seconds * 5 else 'medium'
                })
        
        return sorted(bottlenecks, key=lambda x: x['total_time'], reverse=True)
    
    def save_profile_report(self, filename):
        """Save comprehensive profile report"""
        report = {
            'timing_summary': self.get_timing_summary(),
            'bottlenecks': self.identify_bottlenecks(),
            'call_counts': dict(self.call_counts),
            'report_generated': time.time()
        }
        
        import json
        with open(filename, 'w') as f:
            json.dump(report, f, indent=2, default=str)

# Windows-specific performance monitoring
class WindowsPerformanceMonitor:
    """Monitor Windows-specific performance metrics"""
    
    def __init__(self):
        self.counters = {}
        self.monitoring = False
        self.monitor_thread = None
        
    def start_monitoring(self, interval=1.0):
        """Start performance monitoring"""
        if self.monitoring:
            return
        
        self.monitoring = True
        self.monitor_thread = threading.Thread(
            target=self._monitoring_worker,
            args=(interval,),
            daemon=True
        )
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """Stop performance monitoring"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
    
    def _monitoring_worker(self, interval):
        """Background monitoring worker"""
        try:
            import win32pdh
            import win32pdhutil
            
            # Initialize performance counters
            counters = [
                r'\Process(python)\% Processor Time',
                r'\Process(python)\Working Set',
                r'\Process(python)\Handle Count',
                r'\Process(python)\Thread Count'
            ]
            
            query = win32pdh.OpenQuery()
            counter_handles = {}
            
            for counter in counters:
                try:
                    handle = win32pdh.AddCounter(query, counter)
                    counter_handles[counter] = handle
                except:
                    print(f"Failed to add counter: {counter}")
            
            # Collect data
            while self.monitoring:
                try:
                    win32pdh.CollectQueryData(query)
                    
                    for counter, handle in counter_handles.items():
                        try:
                            _, value = win32pdh.GetFormattedCounterValue(handle, win32pdh.PDH_FMT_LONG)
                            
                            if counter not in self.counters:
                                self.counters[counter] = []
                            self.counters[counter].append({
                                'timestamp': time.time(),
                                'value': value
                            })
                            
                        except Exception as e:
                            print(f"Error reading counter {counter}: {e}")
                    
                    time.sleep(interval)
                    
                except Exception as e:
                    print(f"Monitoring error: {e}")
                    time.sleep(interval)
            
            win32pdh.CloseQuery(query)
            
        except ImportError:
            print("win32pdh not available for performance monitoring")
        except Exception as e:
            print(f"Performance monitoring setup failed: {e}")
    
    def get_counter_data(self, counter_name):
        """Get data for specific counter"""
        return self.counters.get(counter_name, [])
    
    def get_average_value(self, counter_name, duration_seconds=60):
        """Get average value for counter over specified duration"""
        data = self.get_counter_data(counter_name)
        if not data:
            return None
        
        cutoff_time = time.time() - duration_seconds
        recent_data = [item for item in data if item['timestamp'] > cutoff_time]
        
        if not recent_data:
            return None
        
        values = [item['value'] for item in recent_data]
        return sum(values) / len(values)

# Example performance analysis
def analyze_excel_performance():
    """Example of comprehensive Excel performance analysis"""
    profiler = PerformanceProfiler()
    monitor = WindowsPerformanceMonitor()
    
    monitor.start_monitoring()
    
    @profiler.profile_function
    @profiler.time_function
    def create_excel_workbook():
        """Create Excel workbook with performance tracking"""
        import win32com.client
        excel = win32com.client.Dispatch('Excel.Application')
        workbook = excel.Workbooks.Add()
        worksheet = workbook.ActiveSheet
        
        # Fill cells with data
        for row in range(1, 101):
            for col in range(1, 11):
                worksheet.Cells(row, col).Value = f"Data_{row}_{col}"
        
        workbook.Close()
        excel.Quit()
        return True
    
    @profiler.time_function
    def batch_excel_operations():
        """Batch Excel operations for performance comparison"""
        import win32com.client
        excel = win32com.client.Dispatch('Excel.Application')
        workbook = excel.Workbooks.Add()
        worksheet = workbook.ActiveSheet
        
        # Batch operation - fill range at once
        data_range = []
        for row in range(1, 101):
            row_data = [f"Batch_{row}_{col}" for col in range(1, 11)]
            data_range.append(row_data)
        
        # Set range value in one operation
        worksheet.Range("A1:J100").Value = data_range
        
        workbook.Close()
        excel.Quit()
        return True
    
    # Performance comparison
    print("Running individual cell operations...")
    profiler.start_timer("individual_operations")
    create_excel_workbook()
    profiler.stop_timer("individual_operations")
    
    print("Running batch operations...")
    profiler.start_timer("batch_operations")
    batch_excel_operations()
    profiler.stop_timer("batch_operations")
    
    monitor.stop_monitoring()
    
    # Analyze results
    timing_summary = profiler.get_timing_summary()
    bottlenecks = profiler.identify_bottlenecks()
    
    print("\nPerformance Analysis Results:")
    print("=" * 50)
    
    for name, stats in timing_summary.items():
        print(f"\n{name}:")
        print(f"  Average time: {stats['average']:.4f}s")
        print(f"  Total time: {stats['total']:.4f}s")
        print(f"  Call count: {stats['count']}")
    
    if bottlenecks:
        print("\nBottlenecks identified:")
        for bottleneck in bottlenecks:
            print(f"  {bottleneck['function']}: {bottleneck['average_time']:.4f}s average")
    
    # Save detailed report
    profiler.save_profile_report('performance_analysis.json')
```

### 3. System-Level Debugging

#### 3.1 Windows Event Log Integration

**Advanced Event Log Debugging**
```python
import win32evtlog
import win32api
import win32con
import win32security
import winerror
import time
import threading
from datetime import datetime, timedelta

class WindowsEventLogDebugger:
    """Advanced Windows Event Log debugging and monitoring"""
    
    def __init__(self):
        self.event_handlers = {}
        self.monitoring_threads = {}
        self.log_sources = {}
        
    def create_event_source(self, source_name, log_name='Application'):
        """Create custom event source for application logging"""
        try:
            # Register event source
            key_path = f"SYSTEM\\CurrentControlSet\\Services\\EventLog\\{log_name}\\{source_name}"
            
            import win32api
            import win32con
            
            key = win32api.RegCreateKey(win32con.HKEY_LOCAL_MACHINE, key_path)
            win32api.RegSetValueEx(key, "EventMessageFile", 0, win32con.REG_SZ, 
                                 "%SystemRoot%\\System32\\kernel32.dll")
            win32api.RegSetValueEx(key, "TypesSupported", 0, win32con.REG_DWORD, 7)
            win32api.RegCloseKey(key)
            
            self.log_sources[source_name] = log_name
            return True
            
        except Exception as e:
            print(f"Failed to create event source {source_name}: {e}")
            return False
    
    def log_debug_event(self, source_name, message, event_type=win32evtlog.EVENTLOG_INFORMATION_TYPE, event_id=1000):
        """Log custom debug event"""
        try:
            if source_name not in self.log_sources:
                self.create_event_source(source_name)
            
            handle = win32evtlog.RegisterEventSource(None, source_name)
            if handle:
                win32evtlog.ReportEvent(
                    handle,
                    event_type,
                    0,  # category
                    event_id,
                    None,  # user SID
                    [message]
                )
                win32evtlog.DeregisterEventSource(handle)
                return True
                
        except Exception as e:
            print(f"Failed to log event: {e}")
            
        return False
    
    def monitor_event_log(self, log_name='Application', callback=None, filters=None):
        """Monitor Windows Event Log for specific events"""
        def monitoring_worker():
            try:
                # Open event log
                handle = win32evtlog.OpenEventLog(None, log_name)
                if not handle:
                    print(f"Failed to open event log: {log_name}")
                    return
                
                # Get current record count
                last_record = win32evtlog.GetNumberOfEventLogRecords(handle)
                
                while log_name in self.monitoring_threads:
                    try:
                        current_records = win32evtlog.GetNumberOfEventLogRecords(handle)
                        
                        if current_records > last_record:
                            # Read new events
                            flags = win32evtlog.EVENTLOG_BACKWARDS_READ | win32evtlog.EVENTLOG_SEQUENTIAL_READ
                            events = win32evtlog.ReadEventLog(handle, flags, 0)
                            
                            for event in events:
                                if self._should_process_event(event, filters):
                                    if callback:
                                        callback(event)
                                    else:
                                        self._default_event_handler(event)
                            
                            last_record = current_records
                        
                        time.sleep(1)  # Check every second
                        
                    except Exception as e:
                        print(f"Error reading event log: {e}")
                        time.sleep(5)
                
                win32evtlog.CloseEventLog(handle)
                
            except Exception as e:
                print(f"Event log monitoring failed: {e}")
        
        # Start monitoring thread
        thread = threading.Thread(target=monitoring_worker, daemon=True)
        self.monitoring_threads[log_name] = thread
        thread.start()
        
        return thread
    
    def stop_monitoring(self, log_name):
        """Stop monitoring specific event log"""
        if log_name in self.monitoring_threads:
            del self.monitoring_threads[log_name]
    
    def _should_process_event(self, event, filters):
        """Check if event matches filters"""
        if not filters:
            return True
        
        # Apply filters
        if 'source' in filters and event.SourceName not in filters['source']:
            return False
        
        if 'event_type' in filters and event.EventType not in filters['event_type']:
            return False
        
        if 'event_id' in filters and event.EventID not in filters['event_id']:
            return False
        
        return True
    
    def _default_event_handler(self, event):
        """Default event handler"""
        event_time = datetime.fromtimestamp(int(event.TimeGenerated))
        print(f"Event: {event.SourceName} - {event.EventID} - {event_time}")
    
    def search_event_logs(self, search_criteria, time_range_hours=24):
        """Search event logs with specific criteria"""
        results = []
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=time_range_hours)
        
        try:
            logs_to_search = ['Application', 'System', 'Security']
            
            for log_name in logs_to_search:
                try:
                    handle = win32evtlog.OpenEventLog(None, log_name)
                    if not handle:
                        continue
                    
                    flags = win32evtlog.EVENTLOG_BACKWARDS_READ | win32evtlog.EVENTLOG_SEQUENTIAL_READ
                    events = win32evtlog.ReadEventLog(handle, flags, 0)
                    
                    for event in events:
                        event_time = datetime.fromtimestamp(int(event.TimeGenerated))
                        
                        # Check time range
                        if event_time < start_time:
                            break
                        
                        # Check search criteria
                        if self._matches_search_criteria(event, search_criteria):
                            results.append({
                                'log_name': log_name,
                                'source': event.SourceName,
                                'event_id': event.EventID,
                                'event_type': event.EventType,
                                'time': event_time,
                                'message': self._get_event_message(event)
                            })
                    
                    win32evtlog.CloseEventLog(handle)
                    
                except Exception as e:
                    print(f"Error searching {log_name}: {e}")
        
        except Exception as e:
            print(f"Event log search failed: {e}")
        
        return results
    
    def _matches_search_criteria(self, event, criteria):
        """Check if event matches search criteria"""
        if 'source' in criteria and criteria['source'].lower() not in event.SourceName.lower():
            return False
        
        if 'event_id' in criteria and event.EventID != criteria['event_id']:
            return False
        
        if 'keywords' in criteria:
            message = self._get_event_message(event)
            for keyword in criteria['keywords']:
                if keyword.lower() in message.lower():
                    return True
            return False
        
        return True
    
    def _get_event_message(self, event):
        """Extract message from event"""
        try:
            if hasattr(event, 'StringInserts') and event.StringInserts:
                return ' '.join(event.StringInserts)
            else:
                return f"Event ID: {event.EventID}"
        except:
            return "Unable to retrieve message"

# Example usage
def debug_application_with_event_logs():
    """Example of using event logs for debugging"""
    debugger = WindowsEventLogDebugger()
    
    # Create custom event source
    app_name = "PyWin32DebugApp"
    debugger.create_event_source(app_name)
    
    # Log application start
    debugger.log_debug_event(app_name, "Application debugging started", 
                           win32evtlog.EVENTLOG_INFORMATION_TYPE, 1001)
    
    try:
        # Simulate application operations
        import win32com.client
        
        debugger.log_debug_event(app_name, "Creating Excel application", 
                               win32evtlog.EVENTLOG_INFORMATION_TYPE, 1002)
        
        excel = win32com.client.Dispatch('Excel.Application')
        
        debugger.log_debug_event(app_name, "Excel application created successfully", 
                               win32evtlog.EVENTLOG_INFORMATION_TYPE, 1003)
        
        # Perform operations that might fail
        try:
            workbook = excel.Workbooks.Open("NonExistentFile.xlsx")
        except Exception as e:
            debugger.log_debug_event(app_name, f"Failed to open workbook: {e}", 
                                   win32evtlog.EVENTLOG_ERROR_TYPE, 2001)
        
        excel.Quit()
        
    except Exception as e:
        debugger.log_debug_event(app_name, f"Application error: {e}", 
                               win32evtlog.EVENTLOG_ERROR_TYPE, 2000)
    
    finally:
        debugger.log_debug_event(app_name, "Application debugging completed", 
                               win32evtlog.EVENTLOG_INFORMATION_TYPE, 1004)
    
    # Search for application events
    search_results = debugger.search_event_logs({
        'source': app_name,
        'keywords': ['error', 'failed']
    }, time_range_hours=1)
    
    print(f"Found {len(search_results)} relevant events:")
    for event in search_results:
        print(f"  {event['time']}: {event['message']}")
```

## Practical Exercises

### Exercise 1: Debug Session Framework
Create a comprehensive debugging framework for pywin32 applications.

**Requirements:**
- Implement automatic error detection and logging
- Include memory leak detection capabilities
- Support performance profiling and analysis
- Create debugging report generation
- Include remote debugging capabilities

### Exercise 2: Performance Optimization Toolkit
Build a toolkit for analyzing and optimizing pywin32 application performance.

**Requirements:**
- Implement automated performance testing
- Create bottleneck identification system
- Include memory usage optimization
- Support batch operation optimization
- Provide performance comparison tools

### Exercise 3: Production Monitoring System
Develop a monitoring system for production pywin32 applications.

**Requirements:**
- Real-time performance monitoring
- Automatic error detection and alerting
- Resource usage tracking
- Health check implementation
- Performance trend analysis

### Exercise 4: Advanced Error Recovery System
Create an advanced error recovery and self-healing system.

**Requirements:**
- Implement automatic error classification
- Create recovery strategies for common errors
- Include rollback mechanisms
- Support graceful degradation
- Provide error pattern analysis

## Best Practices

### 1. Debugging Strategy

**Systematic Approach**
- Start with high-level analysis before diving into details
- Use logging extensively but efficiently
- Implement comprehensive error handling
- Create reproducible test cases
- Document debugging sessions and solutions

**Tool Selection**
- Use appropriate debugging tools for each scenario
- Combine multiple debugging techniques
- Leverage Windows-specific debugging capabilities
- Implement custom debugging utilities when needed
- Keep debugging overhead minimal in production

### 2. Performance Optimization

**Measurement-Driven Optimization**
- Always measure before optimizing
- Focus on the biggest bottlenecks first
- Use statistical analysis for performance data
- Implement A/B testing for optimizations
- Monitor performance in production environments

**Resource Management**
- Implement proper resource cleanup
- Use object pooling for expensive objects
- Monitor memory usage patterns
- Optimize for specific usage scenarios
- Consider caching strategies carefully

### 3. Production Debugging

**Observability**
- Implement comprehensive logging
- Use structured logging formats
- Include correlation IDs for request tracking
- Monitor key performance indicators
- Create dashboards for system health

**Error Handling**
- Implement graceful error handling
- Provide meaningful error messages
- Include context information in errors
- Implement retry mechanisms for transient errors
- Log errors with sufficient detail for debugging

## Common Pitfalls

### 1. Over-Debugging
- **Problem**: Excessive debugging overhead in production
- **Solution**: Use conditional debugging and performance-aware logging

### 2. Insufficient Context
- **Problem**: Errors without enough context for diagnosis
- **Solution**: Include comprehensive context information in error reports

### 3. Memory Leak Ignorance
- **Problem**: Not monitoring for memory leaks in long-running processes
- **Solution**: Implement continuous memory monitoring and leak detection

### 4. Performance Regression
- **Problem**: Performance degradation going unnoticed
- **Solution**: Implement automated performance testing and monitoring

### 5. Security Through Obscurity
- **Problem**: Hiding error details for security but making debugging impossible
- **Solution**: Implement secure logging that provides enough detail for debugging

## Capstone Project: Diagnostic and Troubleshooting Toolkit

Create a comprehensive diagnostic and troubleshooting toolkit for pywin32 applications.

### Project Requirements

**Core Features:**
- Automated error detection and classification
- Performance monitoring and analysis
- Memory leak detection and reporting
- Resource usage tracking
- Event log integration and analysis
- Remote debugging capabilities
- Automated testing and validation

**Technical Specifications:**
- Support for multiple application types
- Real-time monitoring capabilities
- Historical data analysis and trending
- Automated report generation
- Integration with common development tools
- Extensible plugin architecture
- Web-based dashboard interface

**Advanced Features:**
- Machine learning-based anomaly detection
- Predictive failure analysis
- Automated recovery mechanisms
- Integration with CI/CD pipelines
- Multi-system monitoring support
- Advanced visualization capabilities

### Implementation Guide

1. **Architecture Design**
   - Design monitoring and debugging architecture
   - Plan data collection and storage strategy
   - Design user interfaces and APIs
   - Plan deployment and distribution

2. **Core Development**
   - Implement monitoring agents
   - Create analysis engines
   - Build reporting systems
   - Develop user interfaces

3. **Testing and Validation**
   - Create comprehensive test scenarios
   - Validate monitoring accuracy
   - Test performance impact
   - Verify security and privacy

4. **Documentation and Training**
   - Create user documentation
   - Write troubleshooting guides
   - Provide training materials
   - Include best practices documentation

## Module Summary

In this module, you've mastered:

- **Advanced Debugging Techniques**: Comprehensive debugging strategies, memory analysis, and resource tracking for complex pywin32 applications
- **Performance Analysis**: Systematic performance profiling, bottleneck identification, and optimization techniques
- **System-Level Debugging**: Integration with Windows Event Logs, system monitoring, and production debugging strategies
- **Tool Development**: Creation of custom debugging and monitoring tools for enterprise environments
- **Best Practices**: Professional approaches to debugging, performance optimization, and production monitoring

You're now equipped with expert-level debugging and troubleshooting skills that enable you to maintain, optimize, and scale enterprise pywin32 applications. These skills are essential for building robust, production-ready Windows automation solutions.

**Next Module**: [5.4 Integration Patterns and Architecture](./5.4%20Integration%20Patterns%20and%20Architecture.md)
